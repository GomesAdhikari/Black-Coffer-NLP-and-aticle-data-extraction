{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41afaf8f-da0b-47fb-be81-2fd2cf62b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from nltk.corpus import cmudict\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b919d599-5b64-419d-a01f-291cb7c51477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Netclan20241159</td>\n",
       "      <td>https://insights.blackcoffer.com/population-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Netclan20241160</td>\n",
       "      <td>https://insights.blackcoffer.com/google-lsa-ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Netclan20241161</td>\n",
       "      <td>https://insights.blackcoffer.com/healthcare-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Netclan20241162</td>\n",
       "      <td>https://insights.blackcoffer.com/budget-sales-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Netclan20241163</td>\n",
       "      <td>https://insights.blackcoffer.com/amazon-buy-bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              URL_ID                                                URL\n",
       "0    Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...\n",
       "1    Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...\n",
       "2    Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...\n",
       "3    Netclan20241020  https://insights.blackcoffer.com/efficient-pro...\n",
       "4    Netclan20241021  https://insights.blackcoffer.com/development-o...\n",
       "..               ...                                                ...\n",
       "142  Netclan20241159  https://insights.blackcoffer.com/population-an...\n",
       "143  Netclan20241160  https://insights.blackcoffer.com/google-lsa-ap...\n",
       "144  Netclan20241161  https://insights.blackcoffer.com/healthcare-da...\n",
       "145  Netclan20241162  https://insights.blackcoffer.com/budget-sales-...\n",
       "146  Netclan20241163  https://insights.blackcoffer.com/amazon-buy-bo...\n",
       "\n",
       "[147 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Input.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d52d07-431a-4dc7-8539-f664b2387b3e",
   "metadata": {},
   "source": [
    "# Creating function for data extraction of article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9983218-2b25-4b33-ab30-c2475b3be36c",
   "metadata": {},
   "source": [
    "# Extracting data in .txt format from each article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6523f6-79b6-4ef4-a2b5-395a69423085",
   "metadata": {},
   "source": [
    "# Creating a title feature in Dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74874a65-1e93-40a7-b1a0-d6b623d99157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved article 'Securing Sensitive Financial Data with Privacy-Preserving Machine Learning for Predictive Analytics' to article data/Securing_Sensitive_Financial_Data_with_Privacy-Preserving_Machine_Learning_for_Predictive_Analytics.txt\n",
      "Saved article 'Development of EA Robot for Automated Trading' to article data/Development_of_EA_Robot_for_Automated_Trading.txt\n",
      "Saved article 'ROAS Dashboard for Campaign-Wise Google Ads Budget Tracking Using Google Ads AP' to article data/ROAS_Dashboard_for_Campaign-Wise_Google_Ads_Budget_Tracking_Using_Google_Ads_AP.txt\n",
      "Failed to retrieve article from https://insights.blackcoffer.com/efficient-processing-and-analysis-of-financial-data-from-pdf-files-addressing-formatting-inconsistencies-and-ensuring-data-integrity-for-a-toyota-dealership-management-firm/. Error: [Errno 2] No such file or directory: 'article data/Efficient_Processing_and_Analysis_of_Financial_Data_from_PDF_Files_Addressing_Formatting_Inconsistencies_and_Ensuring_Data_Integrity_for_a_Toyota_Dealership_Management_Firm.txt'\n",
      "Saved article 'ROAS Dashboard for Campaign-Wise Google Ads Budget Tracking Using Google Ads AP' to article data/ROAS_Dashboard_for_Campaign-Wise_Google_Ads_Budget_Tracking_Using_Google_Ads_AP.txt\n",
      "Saved article 'AI and ML-Based YouTube Analytics and Content Creation Tool for Optimizing Subscriber Engagement and Content Strategy' to article data/AI_and_ML-Based_YouTube_Analytics_and_Content_Creation_Tool_for_Optimizing_Subscriber_Engagement_and_Content_Strategy.txt\n",
      "Saved article 'Enhancing Front-End Features and Functionality for Improved User Experience and Dashboard Accuracy in Partner Hospital Application' to article data/Enhancing_Front-End_Features_and_Functionality_for_Improved_User_Experience_and_Dashboard_Accuracy_in_Partner_Hospital_Application.txt\n",
      "Saved article 'Analyzing the Impact of Positive Emotions and Pandemic Severity on Mental Health and Resilience Among Entrepreneurs: Insights and Predictive Modeling' to article data/Analyzing_the_Impact_of_Positive_Emotions_and_Pandemic_Severity_on_Mental_Health_and_Resilience_Among_Entrepreneurs_Insights_and_Predictive_Modeling.txt\n",
      "Saved article 'AI and ML-Based YouTube Analytics and Content Creation Tool for Optimizing Subscriber Engagement and Content Strategy' to article data/AI_and_ML-Based_YouTube_Analytics_and_Content_Creation_Tool_for_Optimizing_Subscriber_Engagement_and_Content_Strategy.txt\n",
      "Saved article 'Dynamic, Brand-Centric Dashboard for Automotive Dealerships: PDF to Financial Insights with Flask-React Architecture and AWS Cloud Hosting' to article data/Dynamic,_Brand-Centric_Dashboard_for_Automotive_Dealerships_PDF_to_Financial_Insights_with_Flask-React_Architecture_and_AWS_Cloud_Hosting.txt\n",
      "Saved article 'Transforming and Managing a Large-Scale SQL Pedigree Database to Neo4j Graph DB' to article data/Transforming_and_Managing_a_Large-Scale_SQL_Pedigree_Database_to_Neo4j_Graph_DB.txt\n",
      "Saved article 'Enhancing Front-End Features and Functionality for Improved User Experience and Dashboard Accuracy in Partner Hospital Application' to article data/Enhancing_Front-End_Features_and_Functionality_for_Improved_User_Experience_and_Dashboard_Accuracy_in_Partner_Hospital_Application.txt\n",
      "Saved article 'Enhancing Model Accuracy from 58% to Over 90%: Strategies for Improving Predictive Performance' to article data/Enhancing_Model_Accuracy_from_58%_to_Over_90%_Strategies_for_Improving_Predictive_Performance.txt\n",
      "Failed to retrieve article from https://insights.blackcoffer.com/efficient-processing-and-analysis-of-financial-data-from-pdf-files-addressing-formatting-inconsistencies-and-ensuring-data-integrity-for-a-toyota-dealership-management-firm/. Error: [Errno 2] No such file or directory: 'article data/Efficient_Processing_and_Analysis_of_Financial_Data_from_PDF_Files_Addressing_Formatting_Inconsistencies_and_Ensuring_Data_Integrity_for_a_Toyota_Dealership_Management_Firm.txt'\n",
      "Saved article 'Cloud-Based Data Modeling and Analysis Platform with Drag-and-Drop Interface and OpenAI API Integration for Simulation Insights' to article data/Cloud-Based_Data_Modeling_and_Analysis_Platform_with_Drag-and-Drop_Interface_and_OpenAI_API_Integration_for_Simulation_Insights.txt\n",
      "Saved article 'Enhancing Data Collection for Research Institutions: Addressing Survey Fatigue and Incorporating Verbal Communication for Richer Insights' to article data/Enhancing_Data_Collection_for_Research_Institutions_Addressing_Survey_Fatigue_and_Incorporating_Verbal_Communication_for_Richer_Insights.txt\n",
      "Saved article 'Voter Profile Analysis and Search Application for Targeted Campaign Engagement Using Government Voter Data' to article data/Voter_Profile_Analysis_and_Search_Application_for_Targeted_Campaign_Engagement_Using_Government_Voter_Data.txt\n",
      "Saved article 'Advanced Data Visualization Solutions for Monitoring Key Business Metrics with Integrated, Interactive Dashboards' to article data/Advanced_Data_Visualization_Solutions_for_Monitoring_Key_Business_Metrics_with_Integrated,_Interactive_Dashboards.txt\n",
      "Saved article 'AI-Driven Backend for Audio-to-Text Conversion and Analytical Assessment in Pharmaceutical Practice' to article data/AI-Driven_Backend_for_Audio-to-Text_Conversion_and_Analytical_Assessment_in_Pharmaceutical_Practice.txt\n",
      "Saved article 'Anomaly Detection and Analysis for Enhanced Data Integrity and User Experience on Bright Data’s Website' to article data/Anomaly_Detection_and_Analysis_for_Enhanced_Data_Integrity_and_User_Experience_on_Bright_Data’s_Website.txt\n",
      "Saved article 'Automated Job Data Import and Management Solution for Enhanced Efficiency' to article data/Automated_Job_Data_Import_and_Management_Solution_for_Enhanced_Efficiency.txt\n",
      "Saved article 'PowerBI REST API – Fetching Dataflow and Refresh Schedules with semantic models' to article data/PowerBI_REST_API_–_Fetching_Dataflow_and_Refresh_Schedules_with_semantic_models.txt\n",
      "Saved article 'Advanced Patient Data Analysis Solution for Trend Identification and Improved Healthcare Outcome' to article data/Advanced_Patient_Data_Analysis_Solution_for_Trend_Identification_and_Improved_Healthcare_Outcome.txt\n",
      "Saved article 'BERT-Based Classification of Individuals and Organizations into Two Categories Using Natural Language Processing' to article data/BERT-Based_Classification_of_Individuals_and_Organizations_into_Two_Categories_Using_Natural_Language_Processing.txt\n",
      "Saved article 'Efficient Coach Allocation System for Sports Coaching Organization' to article data/Efficient_Coach_Allocation_System_for_Sports_Coaching_Organization.txt\n",
      "Saved article 'Data Analytics and Optimization Solution for Enhancing Renewable Energy Efficiency' to article data/Data_Analytics_and_Optimization_Solution_for_Enhancing_Renewable_Energy_Efficiency.txt\n",
      "Saved article 'Cloud-Based Web Application for Financial Data Processing and Visualization of S&P 500 Metrics' to article data/Cloud-Based_Web_Application_for_Financial_Data_Processing_and_Visualization_of_S&P_500_Metrics.txt\n",
      "Saved article 'Sports Prediction Model for Multiple Sports Leagues' to article data/Sports_Prediction_Model_for_Multiple_Sports_Leagues.txt\n",
      "Saved article 'Comprehensive Analysis of Solana and Ethereum Contributors Using GitHub API with Comparative Study of 1000 Random GitHub Profiles' to article data/Comprehensive_Analysis_of_Solana_and_Ethereum_Contributors_Using_GitHub_API_with_Comparative_Study_of_1000_Random_GitHub_Profiles.txt\n",
      "Saved article 'Building Custom TFLite Models and Benchmarking on VOXL2 Chips' to article data/Building_Custom_TFLite_Models_and_Benchmarking_on_VOXL2_Chips.txt\n",
      "Saved article 'Data Studio Dashboard with a data pipeline tool synced with Podio using custom Webhooks and Google Cloud Function' to article data/Data_Studio_Dashboard_with_a_data_pipeline_tool_synced_with_Podio_using_custom_Webhooks_and_Google_Cloud_Function.txt\n",
      "Saved article 'Time Series Analysis and Trend Forecasting Solution for Predicting News Trends' to article data/Time_Series_Analysis_and_Trend_Forecasting_Solution_for_Predicting_News_Trends.txt\n",
      "Saved article 'Google LSA Ads (Google Local Service Ads) – ETL tools and Dashboards' to article data/Google_LSA_Ads_(Google_Local_Service_Ads)_–_ETL_tools_and_Dashboards.txt\n",
      "Saved article 'Data from CRM via Zapier to Google Sheets (Dynamic) to PowerBI' to article data/Data_from_CRM_via_Zapier_to_Google_Sheets_(Dynamic)_to_PowerBI.txt\n",
      "Saved article 'Building a Real-Time Log File Visualization Dashboard in Kibana' to article data/Building_a_Real-Time_Log_File_Visualization_Dashboard_in_Kibana.txt\n",
      "Saved article 'Steps to Convert a Node.js API to Python for AWS Lambda Deployment' to article data/Steps_to_Convert_a_Node.js_API_to_Python_for_AWS_Lambda_Deployment.txt\n",
      "Saved article 'CRM, Monday.com via Zapier to Power BI Dashboard' to article data/CRM,_Monday.com_via_Zapier_to_Power_BI_Dashboard.txt\n",
      "Saved article 'AI Bot Audio to audio' to article data/AI_Bot_Audio_to_audio.txt\n",
      "Saved article 'Data Management for a Political SaaS Application' to article data/Data_Management_for_a_Political_SaaS_Application.txt\n",
      "Saved article 'Monday.com to KPI Dashboard to manage, view, and generate insights from the CRM data' to article data/Monday.com_to_KPI_Dashboard_to_manage,_view,_and_generate_insights_from_the_CRM_data.txt\n",
      "Saved article 'Ad Networks Marketing Campaign Data Dashboard in Looker (Google Data Studio)' to article data/Ad_Networks_Marketing_Campaign_Data_Dashboard_in_Looker_(Google_Data_Studio).txt\n",
      "Saved article 'AI Chatbot using LLM, Langchain, LLama' to article data/AI_Chatbot_using_LLM,_Langchain,_LLama.txt\n",
      "Saved article 'Recommendation Engine for Insurance Sector to Expand Business in the Rural Area' to article data/Recommendation_Engine_for_Insurance_Sector_to_Expand_Business_in_the_Rural_Area.txt\n",
      "Saved article 'Analyzing the Impact of Female CEO Appointments on Company Stock Prices' to article data/Analyzing_the_Impact_of_Female_CEO_Appointments_on_Company_Stock_Prices.txt\n",
      "Saved article 'Building an Analytics Dashboard with a PDF Parsing Pipeline for Data Extraction' to article data/Building_an_Analytics_Dashboard_with_a_PDF_Parsing_Pipeline_for_Data_Extraction.txt\n",
      "Saved article 'Data Warehouse to Google Data Studio (Looker) Dashboard' to article data/Data_Warehouse_to_Google_Data_Studio_(Looker)_Dashboard.txt\n",
      "Saved article 'Healthcare AI ChatBot using LLAMA, LLM, Langchain' to article data/Healthcare_AI_ChatBot_using_LLAMA,_LLM,_Langchain.txt\n",
      "Saved article 'Department-Wise KPI Tracking Dashboard with Technician Performance Analysis for AtoZ Dependable Service' to article data/Department-Wise_KPI_Tracking_Dashboard_with_Technician_Performance_Analysis_for_AtoZ_Dependable_Service.txt\n",
      "Saved article 'Create a Knowledge Graph to Provide Real-time Analytics, Recommendations, and a Single Source of Truth' to article data/Create_a_Knowledge_Graph_to_Provide_Real-time_Analytics,_Recommendations,_and_a_Single_Source_of_Truth.txt\n",
      "Saved article 'Advanced AI for Handgun Detection' to article data/Advanced_AI_for_Handgun_Detection.txt\n",
      "Saved article 'Using Graph Technology to Create Single Customer View.' to article data/Using_Graph_Technology_to_Create_Single_Customer_View..txt\n",
      "Saved article 'AI solution for a Technology, Information and Internet firm' to article data/AI_solution_for_a_Technology,_Information_and_Internet_firm.txt\n",
      "Saved article 'Advanced AI for Pedestrian Crossing Safety' to article data/Advanced_AI_for_Pedestrian_Crossing_Safety.txt\n",
      "Saved article 'AI-Based Algorithmic Trading Bot for Forex' to article data/AI-Based_Algorithmic_Trading_Bot_for_Forex.txt\n",
      "Saved article 'Analytical solution for a tech firm' to article data/Analytical_solution_for_a_tech_firm.txt\n",
      "Saved article 'AI Solutions for Foreign Exchange – An Automated Algo Trading Tool' to article data/AI_Solutions_for_Foreign_Exchange_–_An_Automated_Algo_Trading_Tool.txt\n",
      "Saved article 'Advanced AI for Thermal Person Detection' to article data/Advanced_AI_for_Thermal_Person_Detection.txt\n",
      "Saved article 'An ETL solution for an Internet Publishing firm' to article data/An_ETL_solution_for_an_Internet_Publishing_firm.txt\n",
      "Saved article 'Advanced AI for Trading Automation' to article data/Advanced_AI_for_Trading_Automation.txt\n",
      "Saved article 'Golden Record – A knowledge graph database approach to unfold discovery using Neo4j' to article data/Golden_Record_–_A_knowledge_graph_database_approach_to_unfold_discovery_using_Neo4j.txt\n",
      "Saved article 'Advanced AI for Road Cam Threat Detection' to article data/Advanced_AI_for_Road_Cam_Threat_Detection.txt\n",
      "Saved article 'AI agent development and Deployment in Jina AI' to article data/AI_agent_development_and_Deployment_in_Jina_AI.txt\n",
      "Saved article 'AI and NLP-based Solutions to Automate Data Discovery for Venture Capital and Private Equity Principals' to article data/AI_and_NLP-based_Solutions_to_Automate_Data_Discovery_for_Venture_Capital_and_Private_Equity_Principals.txt\n",
      "Saved article 'Equity Waterfalls Model-Based SaaS Application for Real Estate Sector' to article data/Equity_Waterfalls_Model-Based_SaaS_Application_for_Real_Estate_Sector.txt\n",
      "Saved article 'Building a Physics-Informed Neural Network for Circuit Evaluation' to article data/Building_a_Physics-Informed_Neural_Network_for_Circuit_Evaluation.txt\n",
      "Saved article 'Return on Advertising Spend Dashboard: Marketing Automation and Analytics using ETL and Dashboard' to article data/Return_on_Advertising_Spend_Dashboard_Marketing_Automation_and_Analytics_using_ETL_and_Dashboard.txt\n",
      "Saved article 'Ranking customer behaviours for business strategy' to article data/Ranking_customer_behaviours_for_business_strategy.txt\n",
      "Saved article 'Car Detection in Satellite Images' to article data/Car_Detection_in_Satellite_Images.txt\n",
      "Saved article 'Trading Bot for FOREX' to article data/Trading_Bot_for_FOREX.txt\n",
      "Saved article 'ETL and MLOps Infrastructure for Blockchain Analytics' to article data/ETL_and_MLOps_Infrastructure_for_Blockchain_Analytics.txt\n",
      "Saved article 'Algorithmic trading for multiple commodities markets, like Forex, Metals, Energy, etc.' to article data/Algorithmic_trading_for_multiple_commodities_markets,_like_Forex,_Metals,_Energy,_etc..txt\n",
      "Saved article 'Connecting MongoDB Database to Power BI Dashboard: Dashboard Automation' to article data/Connecting_MongoDB_Database_to_Power_BI_Dashboard_Dashboard_Automation.txt\n",
      "Saved article 'An ETL Solution for Currency Data to Google Big Query' to article data/An_ETL_Solution_for_Currency_Data_to_Google_Big_Query.txt\n",
      "Saved article 'Python model for the analysis of sector-specific stock ETFs for investment purposes' to article data/Python_model_for_the_analysis_of_sector-specific_stock_ETFs_for_investment_purposes.txt\n",
      "Saved article 'Design and develop solution to anomaly detection classification problems' to article data/Design_and_develop_solution_to_anomaly_detection_classification_problems.txt\n",
      "Saved article 'Data Transformation' to article data/Data_Transformation.txt\n",
      "Saved article 'KPI Dashboard for Accountants' to article data/KPI_Dashboard_for_Accountants.txt\n",
      "Saved article 'Design & Develop BERT Question Answering model explanations with visualization' to article data/Design_&_Develop_BERT_Question_Answering_model_explanations_with_visualization.txt\n",
      "Saved article 'Medical Classification' to article data/Medical_Classification.txt\n",
      "Saved article 'E-commerce Store Analysis – Purchase Behavior, Ad Spend, Conversion, Traffic, etc…' to article data/E-commerce_Store_Analysis_–_Purchase_Behavior,_Ad_Spend,_Conversion,_Traffic,_etc….txt\n",
      "Saved article 'An agent-based model of a Virtual Power Plant (VPP)' to article data/An_agent-based_model_of_a_Virtual_Power_Plant_(VPP).txt\n",
      "Saved article 'Transform API into SDK library and widget' to article data/Transform_API_into_SDK_library_and_widget.txt\n",
      "Saved article 'A web-based dashboard for the filtered data retrieval of land records' to article data/A_web-based_dashboard_for_the_filtered_data_retrieval_of_land_records.txt\n",
      "Saved article 'Auvik, Connectwise integration in Grafana' to article data/Auvik,_Connectwise_integration_in_Grafana.txt\n",
      "Saved article 'Data integration and big data performance using Elasticsearch' to article data/Data_integration_and_big_data_performance_using_Elasticsearch.txt\n",
      "Saved article 'Web Data Connector' to article data/Web_Data_Connector.txt\n",
      "Saved article 'Integration of video-conferencing data to the existing web app' to article data/Integration_of_video-conferencing_data_to_the_existing_web_app.txt\n",
      "Saved article 'Integration of a product to a cloud-based CRM platform' to article data/Integration_of_a_product_to_a_cloud-based_CRM_platform.txt\n",
      "Saved article 'Dashboard to track the analytics of the website using Google Analytics and Google Tag Manager' to article data/Dashboard_to_track_the_analytics_of_the_website_using_Google_Analytics_and_Google_Tag_Manager.txt\n",
      "Saved article 'Design & develop an app in retool which shows the progress of the added video' to article data/Design_&_develop_an_app_in_retool_which_shows_the_progress_of_the_added_video.txt\n",
      "Saved article 'An AI ML-based web application that detects the correctness of text in a given video' to article data/An_AI_ML-based_web_application_that_detects_the_correctness_of_text_in_a_given_video.txt\n",
      "Saved article 'Optimize the data scraper program to easily accommodate large files and solve OOM errors' to article data/Optimize_the_data_scraper_program_to_easily_accommodate_large_files_and_solve_OOM_errors.txt\n",
      "Saved article 'Power BI Dashboard on Operations, Transactions, and Marketing Data, embedding the Dashboard to Web App' to article data/Power_BI_Dashboard_on_Operations,_Transactions,_and_Marketing_Data,_embedding_the_Dashboard_to_Web_App.txt\n",
      "Saved article 'NFT Data Automation (looksrare), and ETL tool' to article data/NFT_Data_Automation_(looksrare),_and_ETL_tool.txt\n",
      "Saved article 'An app for updating the email id of the user and stripe refund tool using retool' to article data/An_app_for_updating_the_email_id_of_the_user_and_stripe_refund_tool_using_retool.txt\n",
      "Saved article 'Website Tracking and Insights using Google Analytics, & Google Tag Manager' to article data/Website_Tracking_and_Insights_using_Google_Analytics,_&_Google_Tag_Manager.txt\n",
      "Saved article 'Making a robust way to sync data from airtables to mongoDB using python – ETL Solution' to article data/Making_a_robust_way_to_sync_data_from_airtables_to_mongoDB_using_python_–_ETL_Solution.txt\n",
      "Saved article 'Incident Duration Prediction – Infrastructure and Real Estate' to article data/Incident_Duration_Prediction_–_Infrastructure_and_Real_Estate.txt\n",
      "Saved article 'Statistical Data Analysis of Reinforced Concrete' to article data/Statistical_Data_Analysis_of_Reinforced_Concrete.txt\n",
      "Saved article 'AWS Lex Voice and Chatbot' to article data/AWS_Lex_Voice_and_Chatbot.txt\n",
      "Saved article 'Real-time dashboard to monitor infrastructure activity and Machines' to article data/Real-time_dashboard_to_monitor_infrastructure_activity_and_Machines.txt\n",
      "Saved article 'Impact of news, media, and press on innovation, startups, and investments' to article data/Impact_of_news,_media,_and_press_on_innovation,_startups,_and_investments.txt\n",
      "Saved article 'Gangala.in: E-commerce Big Data ETL / ELT Solution and Data Warehouse' to article data/Gangala.in_E-commerce_Big_Data_ETL___ELT_Solution_and_Data_Warehouse.txt\n",
      "Saved article 'MetaBridges API Decentraland Integration – AR, VR' to article data/MetaBridges_API_Decentraland_Integration_–_AR,_VR.txt\n",
      "Saved article 'Microsoft Azure chatbot with LUIS (Language Understanding)' to article data/Microsoft_Azure_chatbot_with_LUIS_(Language_Understanding).txt\n",
      "Saved article 'AWS QuickSight Reporting Dashboard' to article data/AWS_QuickSight_Reporting_Dashboard.txt\n",
      "Saved article 'Database Normalization & Segmentation with Google Data Studio Dashboard Insights' to article data/Database_Normalization_&_Segmentation_with_Google_Data_Studio_Dashboard_Insights.txt\n",
      "Saved article 'Electric Vehicles (EV) Load Management System to Forecast Energy Demand' to article data/Electric_Vehicles_(EV)_Load_Management_System_to_Forecast_Energy_Demand.txt\n",
      "Saved article 'Google Local Service Ads (LSA) Leads Dashboard' to article data/Google_Local_Service_Ads_(LSA)_Leads_Dashboard.txt\n",
      "Saved article 'Power BI dashboard to drive insights from complex data to generate business insights' to article data/Power_BI_dashboard_to_drive_insights_from_complex_data_to_generate_business_insights.txt\n",
      "Saved article 'Google Data Studio Dashboard for Marketing, ads and Traction data' to article data/Google_Data_Studio_Dashboard_for_Marketing,_ads_and_Traction_data.txt\n",
      "Saved article 'Power BI Data-Driven Map Dashboard' to article data/Power_BI_Data-Driven_Map_Dashboard.txt\n",
      "Saved article 'Big Data solution to an online multivendor marketplace eCommerce business' to article data/Big_Data_solution_to_an_online_multivendor_marketplace_eCommerce_business.txt\n",
      "Saved article 'Creating a custom report and dashboard using the data got from Atera API' to article data/Creating_a_custom_report_and_dashboard_using_the_data_got_from_Atera_API.txt\n",
      "Saved article 'Azure Data Lake and Power BI Dashboard' to article data/Azure_Data_Lake_and_Power_BI_Dashboard.txt\n",
      "Saved article 'QuickBooks dashboard to find patterns in finance, sales, and forecasts' to article data/QuickBooks_dashboard_to_find_patterns_in_finance,_sales,_and_forecasts.txt\n",
      "Saved article 'A Leading Hospitality Firm in the USA, Website SEO & Optimization' to article data/A_Leading_Hospitality_Firm_in_the_USA,_Website_SEO_&_Optimization.txt\n",
      "Saved article 'A Leading Musical Instrumental, Website SEO & Optimization' to article data/A_Leading_Musical_Instrumental,_Website_SEO_&_Optimization.txt\n",
      "Saved article 'React Native Apps in the Development Portfolio' to article data/React_Native_Apps_in_the_Development_Portfolio.txt\n",
      "Saved article 'Marketing, sales, and financial data business dashboard (Wink Report)' to article data/Marketing,_sales,_and_financial_data_business_dashboard_(Wink_Report).txt\n",
      "Saved article 'Lipsync Automation for Celebrities and Influencers' to article data/Lipsync_Automation_for_Celebrities_and_Influencers.txt\n",
      "Saved article 'Google Data Studio Pipeline with GCP/MySQL' to article data/Google_Data_Studio_Pipeline_with_GCP_MySQL.txt\n",
      "Saved article 'A Leading Firm in the USA, SEO and Website Optimization' to article data/A_Leading_Firm_in_the_USA,_SEO_and_Website_Optimization.txt\n",
      "Saved article 'Key Audit Matters Predictive Modeling' to article data/Key_Audit_Matters_Predictive_Modeling.txt\n",
      "Saved article 'Immigration Datawarehouse & AI-based recommendations' to article data/Immigration_Datawarehouse_&_AI-based_recommendations.txt\n",
      "Saved article 'Splitting of Songs into its Vocals and Instrumental' to article data/Splitting_of_Songs_into_its_Vocals_and_Instrumental.txt\n",
      "Saved article 'A Leading Firm in the USA, Website SEO & Optimization' to article data/A_Leading_Firm_in_the_USA,_Website_SEO_&_Optimization.txt\n",
      "Saved article 'A Leading Law Firm in the USA, Website SEO & Optimization' to article data/A_Leading_Law_Firm_in_the_USA,_Website_SEO_&_Optimization.txt\n",
      "Saved article 'AI and ML technologies to Evaluate Learning Assessments' to article data/AI_and_ML_technologies_to_Evaluate_Learning_Assessments.txt\n",
      "Saved article 'Datawarehouse, and Recommendations Engine for AirBNB' to article data/Datawarehouse,_and_Recommendations_Engine_for_AirBNB.txt\n",
      "Saved article 'Real Estate Data Warehouse' to article data/Real_Estate_Data_Warehouse.txt\n",
      "Saved article 'Traction Dashboards of Marketing Campaigns and Posts' to article data/Traction_Dashboards_of_Marketing_Campaigns_and_Posts.txt\n",
      "Saved article 'Google Local Service Ads (LSA) Data Warehouse' to article data/Google_Local_Service_Ads_(LSA)_Data_Warehouse.txt\n",
      "Saved article 'Google LSA API Data Automation and Dashboarding' to article data/Google_LSA_API_Data_Automation_and_Dashboarding.txt\n",
      "Saved article 'CallRail, Analytics & Leads Report Alert' to article data/CallRail,_Analytics_&_Leads_Report_Alert.txt\n",
      "Saved article 'Sentimental Analysis on Shareholder Letter of Companies' to article data/Sentimental_Analysis_on_Shareholder_Letter_of_Companies.txtSaved article 'Marketing Ads Leads Call Status Data Tool to BigQuery' to article data/Marketing_Ads_Leads_Call_Status_Data_Tool_to_BigQuery.txt\n",
      "Saved article 'Population and Community Survey of America' to article data/Population_and_Community_Survey_of_America.txt\n",
      "\n",
      "Saved article 'Stocktwits Data Structurization' to article data/Stocktwits_Data_Structurization.txt\n",
      "Saved article 'Marketing Tool to Notify Leads to Clients over Email and Phone' to article data/Marketing_Tool_to_Notify_Leads_to_Clients_over_Email_and_Phone.txt\n",
      "Saved article 'Healthcare Data Analysis' to article data/Healthcare_Data_Analysis.txt\n",
      "Saved article 'Data ETL: Local Service Ads Leads to BigQuery' to article data/Data_ETL_Local_Service_Ads_Leads_to_BigQuery.txt\n",
      "Saved article 'Marbles Stimulation using python' to article data/Marbles_Stimulation_using_python.txt\n",
      "Saved article 'Google Local Service Ads Missed Calls and Messages Automation Tool' to article data/Google_Local_Service_Ads_Missed_Calls_and_Messages_Automation_Tool.txt\n",
      "Saved article 'Marketing Analytics to Automate Leads Call Status and Reporting' to article data/Marketing_Analytics_to_Automate_Leads_Call_Status_and_Reporting.txt\n",
      "Saved article 'Budget, Sales KPI Dashboard using Power BI' to article data/Budget,_Sales_KPI_Dashboard_using_Power_BI.txt\n",
      "Saved article 'Amazon Buy Bot, an Automation AI tool to Auto-Checkouts' to article data/Amazon_Buy_Bot,_an_Automation_AI_tool_to_Auto-Checkouts.txt\n",
      "                                                   URL  \\\n",
      "0    https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
      "1    https://insights.blackcoffer.com/enhancing-fro...   \n",
      "2    https://insights.blackcoffer.com/roas-dashboar...   \n",
      "3    https://insights.blackcoffer.com/efficient-pro...   \n",
      "4    https://insights.blackcoffer.com/development-o...   \n",
      "..                                                 ...   \n",
      "142  https://insights.blackcoffer.com/population-an...   \n",
      "143  https://insights.blackcoffer.com/google-lsa-ap...   \n",
      "144  https://insights.blackcoffer.com/healthcare-da...   \n",
      "145  https://insights.blackcoffer.com/budget-sales-...   \n",
      "146  https://insights.blackcoffer.com/amazon-buy-bo...   \n",
      "\n",
      "                                            title_file  \n",
      "0    article data/AI_and_ML-Based_YouTube_Analytics...  \n",
      "1    article data/Enhancing_Front-End_Features_and_...  \n",
      "2    article data/ROAS_Dashboard_for_Campaign-Wise_...  \n",
      "3                                                 None  \n",
      "4    article data/Development_of_EA_Robot_for_Autom...  \n",
      "..                                                 ...  \n",
      "142  article data/Population_and_Community_Survey_o...  \n",
      "143  article data/Google_LSA_API_Data_Automation_an...  \n",
      "144          article data/Healthcare_Data_Analysis.txt  \n",
      "145  article data/Budget,_Sales_KPI_Dashboard_using...  \n",
      "146  article data/Amazon_Buy_Bot,_an_Automation_AI_...  \n",
      "\n",
      "[147 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to get article data and save it to a file\n",
    "def get_article_data(url):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "        title = soup.find('h1', class_='entry-title')  \n",
    "        text = soup.find('div', class_='td-pb-span8 td-main-content')\n",
    "        \n",
    "        # If title and text are found\n",
    "        if title and text:\n",
    "            title = title.text.strip()\n",
    "            text = text.text.strip()\n",
    "            filename = title.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\":\", \"\") + '.txt'   \n",
    "            \n",
    "            # Ensure the directory exists\n",
    "            os.makedirs('article data', exist_ok=True)\n",
    "            \n",
    "            # Define file path\n",
    "            file_path = f'article data/{filename}'\n",
    "            \n",
    "            # Save the article to a text file\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"Title: {title}\\n\\n\")\n",
    "                f.write(text)\n",
    "                print(f\"Saved article '{title}' to {file_path}\")\n",
    "                \n",
    "            return file_path  # Return the file path after saving\n",
    "            \n",
    "        return None  # Return None if title or text is not found\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve article from {url}. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to handle the download and saving of articles using ThreadPoolExecutor\n",
    "def save_articles(df):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # Get the list of file paths by applying the get_article_data function to all URLs\n",
    "        file_paths = list(executor.map(get_article_data, df['URL']))\n",
    "        \n",
    "        # Create a new column in the DataFrame for file paths\n",
    "        df['title_file'] = file_paths\n",
    "\n",
    "# Call the function\n",
    "save_articles(df)\n",
    "\n",
    "# Display the DataFrame to verify the file path column\n",
    "print(df[['URL', 'title_file']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33faef8c-6ca4-4dbd-bc4b-9bb105d5d8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60b0bd-d908-4f8e-9bc3-011a76277626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32121477-9712-4e3a-b6a8-5cb99a986866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    article data/AI_and_ML-Based_YouTube_Analytics...\n",
       "1    article data/Enhancing_Front-End_Features_and_...\n",
       "2    article data/ROAS_Dashboard_for_Campaign-Wise_...\n",
       "3                                                 None\n",
       "4    article data/Development_of_EA_Robot_for_Autom...\n",
       "Name: title_file, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_file'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2717eec4-6c83-47fb-bc58-7343ab28d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words: ['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable']\n",
      "Positive Words: ['a+', 'abound', 'abounds', 'abundance', 'abundant']\n"
     ]
    }
   ],
   "source": [
    "# Define the folder path\n",
    "folder_path = 'MasterDictionary/'\n",
    "\n",
    "# Read the negative words file\n",
    "with open(f'{folder_path}/negative-words.txt', 'r') as file:\n",
    "    negative_words = file.read().splitlines()  # Read each line and create a list\n",
    "\n",
    "# Read the positive words file\n",
    "with open(f'{folder_path}/positive-words.txt', 'r') as file:\n",
    "    positive_words = file.read().splitlines()  # Read each line and create a list\n",
    "\n",
    "# Check the results\n",
    "print(\"Negative Words:\", negative_words[:5])  # Print first 5 negative words\n",
    "print(\"Positive Words:\", positive_words[:5])  # Print first 5 positive words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741527a-c65f-4673-af00-21b785f02312",
   "metadata": {},
   "source": [
    "# Making few more features for the feature extraction of the words that is positive words, negative words, complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f4ae771d-d215-47a0-9234-b0a5b47aaa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading None: expected str, bytes or os.PathLike object, not NoneType\n",
      "Error reading None: expected str, bytes or os.PathLike object, not NoneType\n"
     ]
    }
   ],
   "source": [
    "def read_text_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file_path}: {e}\")\n",
    "        return \"\"  # Return an empty string if there's an error\n",
    "\n",
    "# Function to check and extract positive/negative words\n",
    "def find_words(text, word_list):\n",
    "    words_in_text = text.split()  # Split the text into individual words\n",
    "    return [word for word in words_in_text if word.lower() in word_list]\n",
    "\n",
    "# Read the content of each file in the 'file_path' column\n",
    "df['text'] = df['title_file'].apply(read_text_file)\n",
    "\n",
    "# Apply the function to create new columns in the DataFrame for positive and negative words\n",
    "df['positive_words'] = df['text'].apply(lambda x: find_words(x, positive_words))\n",
    "df['negative_words'] = df['text'].apply(lambda x: find_words(x, negative_words))\n",
    "\n",
    "# Optionally, count the number of positive/negative words\n",
    "df['positive_word_count'] = df['positive_words'].apply(len)\n",
    "df['negative_word_count'] = df['negative_words'].apply(len)\n",
    "\n",
    "# Display the dataframe with the new columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c80d7756-19c8-451e-b21b-5a0c271ffe09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>title_file</th>\n",
       "      <th>text</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "      <td>article data/AI_and_ML-Based_YouTube_Analytics...</td>\n",
       "      <td>Title: AI and ML-Based YouTube Analytics and C...</td>\n",
       "      <td>[leading, integrated, Improved]</td>\n",
       "      <td>[Cloud, Cloud]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "      <td>article data/Enhancing_Front-End_Features_and_...</td>\n",
       "      <td>Title: Enhancing Front-End Features and Functi...</td>\n",
       "      <td>[Improved, leading, lead, patient, user-friend...</td>\n",
       "      <td>[static, issues, strictly, issues, strictly, C...</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "      <td>article data/ROAS_Dashboard_for_Campaign-Wise_...</td>\n",
       "      <td>Title: ROAS Dashboard for Campaign-Wise Google...</td>\n",
       "      <td>[leading, efficiently, streamlined, leading, c...</td>\n",
       "      <td>[lacks, difficulties, cloud, slack, failure, C...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "      <td>article data/Development_of_EA_Robot_for_Autom...</td>\n",
       "      <td>Title: Development of EA Robot for Automated T...</td>\n",
       "      <td>[free, free, seamless, free, appropriate, like...</td>\n",
       "      <td>[limited, risk]</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Netclan20241159</td>\n",
       "      <td>https://insights.blackcoffer.com/population-an...</td>\n",
       "      <td>article data/Population_and_Community_Survey_o...</td>\n",
       "      <td>Title: Population and Community Survey of Amer...</td>\n",
       "      <td>[leading, proper, strong, Sublime, Advanced, E...</td>\n",
       "      <td>[unable, Cloud, plot, plot, plot, plot]</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Netclan20241160</td>\n",
       "      <td>https://insights.blackcoffer.com/google-lsa-ap...</td>\n",
       "      <td>article data/Google_LSA_API_Data_Automation_an...</td>\n",
       "      <td>Title: Google LSA API Data Automation and Dash...</td>\n",
       "      <td>[leading, lead, lead, lead, refresh, like, Sub...</td>\n",
       "      <td>[Regression, Cloud, Regression, missed, Cloud,...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Netclan20241161</td>\n",
       "      <td>https://insights.blackcoffer.com/healthcare-da...</td>\n",
       "      <td>article data/Healthcare_Data_Analysis.txt</td>\n",
       "      <td>Title: Healthcare Data Analysis\\n\\nClient Back...</td>\n",
       "      <td>[leading, survivor, better, patient, patient, ...</td>\n",
       "      <td>[died, death, death, manipulation, Death, died...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Netclan20241162</td>\n",
       "      <td>https://insights.blackcoffer.com/budget-sales-...</td>\n",
       "      <td>article data/Budget,_Sales_KPI_Dashboard_using...</td>\n",
       "      <td>Title: Budget, Sales KPI Dashboard using Power...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Netclan20241163</td>\n",
       "      <td>https://insights.blackcoffer.com/amazon-buy-bo...</td>\n",
       "      <td>article data/Amazon_Buy_Bot,_an_Automation_AI_...</td>\n",
       "      <td>Title: Amazon Buy Bot, an Automation AI tool t...</td>\n",
       "      <td>[leading]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              URL_ID                                                URL  \\\n",
       "0    Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
       "1    Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...   \n",
       "2    Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...   \n",
       "3    Netclan20241020  https://insights.blackcoffer.com/efficient-pro...   \n",
       "4    Netclan20241021  https://insights.blackcoffer.com/development-o...   \n",
       "..               ...                                                ...   \n",
       "142  Netclan20241159  https://insights.blackcoffer.com/population-an...   \n",
       "143  Netclan20241160  https://insights.blackcoffer.com/google-lsa-ap...   \n",
       "144  Netclan20241161  https://insights.blackcoffer.com/healthcare-da...   \n",
       "145  Netclan20241162  https://insights.blackcoffer.com/budget-sales-...   \n",
       "146  Netclan20241163  https://insights.blackcoffer.com/amazon-buy-bo...   \n",
       "\n",
       "                                            title_file  \\\n",
       "0    article data/AI_and_ML-Based_YouTube_Analytics...   \n",
       "1    article data/Enhancing_Front-End_Features_and_...   \n",
       "2    article data/ROAS_Dashboard_for_Campaign-Wise_...   \n",
       "3                                                 None   \n",
       "4    article data/Development_of_EA_Robot_for_Autom...   \n",
       "..                                                 ...   \n",
       "142  article data/Population_and_Community_Survey_o...   \n",
       "143  article data/Google_LSA_API_Data_Automation_an...   \n",
       "144          article data/Healthcare_Data_Analysis.txt   \n",
       "145  article data/Budget,_Sales_KPI_Dashboard_using...   \n",
       "146  article data/Amazon_Buy_Bot,_an_Automation_AI_...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Title: AI and ML-Based YouTube Analytics and C...   \n",
       "1    Title: Enhancing Front-End Features and Functi...   \n",
       "2    Title: ROAS Dashboard for Campaign-Wise Google...   \n",
       "3                                                        \n",
       "4    Title: Development of EA Robot for Automated T...   \n",
       "..                                                 ...   \n",
       "142  Title: Population and Community Survey of Amer...   \n",
       "143  Title: Google LSA API Data Automation and Dash...   \n",
       "144  Title: Healthcare Data Analysis\\n\\nClient Back...   \n",
       "145  Title: Budget, Sales KPI Dashboard using Power...   \n",
       "146  Title: Amazon Buy Bot, an Automation AI tool t...   \n",
       "\n",
       "                                        positive_words  \\\n",
       "0                      [leading, integrated, Improved]   \n",
       "1    [Improved, leading, lead, patient, user-friend...   \n",
       "2    [leading, efficiently, streamlined, leading, c...   \n",
       "3                                                   []   \n",
       "4    [free, free, seamless, free, appropriate, like...   \n",
       "..                                                 ...   \n",
       "142  [leading, proper, strong, Sublime, Advanced, E...   \n",
       "143  [leading, lead, lead, lead, refresh, like, Sub...   \n",
       "144  [leading, survivor, better, patient, patient, ...   \n",
       "145                                                 []   \n",
       "146                                          [leading]   \n",
       "\n",
       "                                        negative_words  positive_word_count  \\\n",
       "0                                       [Cloud, Cloud]                    3   \n",
       "1    [static, issues, strictly, issues, strictly, C...                   15   \n",
       "2    [lacks, difficulties, cloud, slack, failure, C...                   10   \n",
       "3                                                   []                    0   \n",
       "4                                      [limited, risk]                   13   \n",
       "..                                                 ...                  ...   \n",
       "142            [unable, Cloud, plot, plot, plot, plot]                   12   \n",
       "143  [Regression, Cloud, Regression, missed, Cloud,...                   19   \n",
       "144  [died, death, death, manipulation, Death, died...                   10   \n",
       "145                                                 []                    0   \n",
       "146                                                 []                    1   \n",
       "\n",
       "     negative_word_count  \n",
       "0                      2  \n",
       "1                      6  \n",
       "2                      8  \n",
       "3                      0  \n",
       "4                      2  \n",
       "..                   ...  \n",
       "142                    6  \n",
       "143                   18  \n",
       "144                    9  \n",
       "145                    0  \n",
       "146                    0  \n",
       "\n",
       "[147 rows x 8 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85a892-c6ae-4a38-8cfe-9a8eacc97d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\gomes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370d96d-6f09-448f-80a7-09b10b13bf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\gomes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\gomes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  \\\n",
      "0    Title: AI and ML-Based YouTube Analytics and C...   \n",
      "1    Title: Enhancing Front-End Features and Functi...   \n",
      "2    Title: ROAS Dashboard for Campaign-Wise Google...   \n",
      "3                                                        \n",
      "4    Title: Development of EA Robot for Automated T...   \n",
      "..                                                 ...   \n",
      "142  Title: Population and Community Survey of Amer...   \n",
      "143  Title: Google LSA API Data Automation and Dash...   \n",
      "144  Title: Healthcare Data Analysis\\n\\nClient Back...   \n",
      "145  Title: Budget, Sales KPI Dashboard using Power...   \n",
      "146  Title: Amazon Buy Bot, an Automation AI tool t...   \n",
      "\n",
      "                                        filtered_words  \n",
      "0    [title, ai, youtube, analytics, content, creat...  \n",
      "1    [title, enhancing, features, functionality, im...  \n",
      "2    [title, roas, dashboard, google, ads, budget, ...  \n",
      "3                                                   []  \n",
      "4    [title, development, ea, robot, automated, tra...  \n",
      "..                                                 ...  \n",
      "142  [title, population, community, survey, america...  \n",
      "143  [title, google, lsa, api, data, automation, da...  \n",
      "144  [title, healthcare, data, analysis, client, ba...  \n",
      "145  [title, budget, sales, kpi, dashboard, using, ...  \n",
      "146  [title, amazon, buy, bot, automation, ai, tool...  \n",
      "\n",
      "[147 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download stopwords if you haven't already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean text by removing stop words\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text.lower())  # Convert to lowercase and tokenize\n",
    "    # Remove stop words and non-alphabetic characters (optional)\n",
    "    filtered_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
    "    return filtered_words\n",
    "\n",
    "# Apply the function to the 'text' column and create a new column 'filtered_words'\n",
    "df['filtered_words'] = df['text'].apply(remove_stopwords)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(df[['text', 'filtered_words']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f72a0bed-018f-4eb7-af47-dd21a38480f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>title_file</th>\n",
       "      <th>text</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>filtered_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "      <td>article data/AI_and_ML-Based_YouTube_Analytics...</td>\n",
       "      <td>Title: AI and ML-Based YouTube Analytics and C...</td>\n",
       "      <td>[leading, integrated, Improved]</td>\n",
       "      <td>[Cloud, Cloud]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, ai, youtube, analytics, content, creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "      <td>article data/Enhancing_Front-End_Features_and_...</td>\n",
       "      <td>Title: Enhancing Front-End Features and Functi...</td>\n",
       "      <td>[Improved, leading, lead, patient, user-friend...</td>\n",
       "      <td>[static, issues, strictly, issues, strictly, C...</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>[title, enhancing, features, functionality, im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "      <td>article data/ROAS_Dashboard_for_Campaign-Wise_...</td>\n",
       "      <td>Title: ROAS Dashboard for Campaign-Wise Google...</td>\n",
       "      <td>[leading, efficiently, streamlined, leading, c...</td>\n",
       "      <td>[lacks, difficulties, cloud, slack, failure, C...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[title, roas, dashboard, google, ads, budget, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "      <td>article data/Development_of_EA_Robot_for_Autom...</td>\n",
       "      <td>Title: Development of EA Robot for Automated T...</td>\n",
       "      <td>[free, free, seamless, free, appropriate, like...</td>\n",
       "      <td>[limited, risk]</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, development, ea, robot, automated, tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Netclan20241159</td>\n",
       "      <td>https://insights.blackcoffer.com/population-an...</td>\n",
       "      <td>article data/Population_and_Community_Survey_o...</td>\n",
       "      <td>Title: Population and Community Survey of Amer...</td>\n",
       "      <td>[leading, proper, strong, Sublime, Advanced, E...</td>\n",
       "      <td>[unable, Cloud, plot, plot, plot, plot]</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>[title, population, community, survey, america...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Netclan20241160</td>\n",
       "      <td>https://insights.blackcoffer.com/google-lsa-ap...</td>\n",
       "      <td>article data/Google_LSA_API_Data_Automation_an...</td>\n",
       "      <td>Title: Google LSA API Data Automation and Dash...</td>\n",
       "      <td>[leading, lead, lead, lead, refresh, like, Sub...</td>\n",
       "      <td>[Regression, Cloud, Regression, missed, Cloud,...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>[title, google, lsa, api, data, automation, da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Netclan20241161</td>\n",
       "      <td>https://insights.blackcoffer.com/healthcare-da...</td>\n",
       "      <td>article data/Healthcare_Data_Analysis.txt</td>\n",
       "      <td>Title: Healthcare Data Analysis\\n\\nClient Back...</td>\n",
       "      <td>[leading, survivor, better, patient, patient, ...</td>\n",
       "      <td>[died, death, death, manipulation, Death, died...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>[title, healthcare, data, analysis, client, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Netclan20241162</td>\n",
       "      <td>https://insights.blackcoffer.com/budget-sales-...</td>\n",
       "      <td>article data/Budget,_Sales_KPI_Dashboard_using...</td>\n",
       "      <td>Title: Budget, Sales KPI Dashboard using Power...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[title, budget, sales, kpi, dashboard, using, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Netclan20241163</td>\n",
       "      <td>https://insights.blackcoffer.com/amazon-buy-bo...</td>\n",
       "      <td>article data/Amazon_Buy_Bot,_an_Automation_AI_...</td>\n",
       "      <td>Title: Amazon Buy Bot, an Automation AI tool t...</td>\n",
       "      <td>[leading]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[title, amazon, buy, bot, automation, ai, tool...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              URL_ID                                                URL  \\\n",
       "0    Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
       "1    Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...   \n",
       "2    Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...   \n",
       "3    Netclan20241020  https://insights.blackcoffer.com/efficient-pro...   \n",
       "4    Netclan20241021  https://insights.blackcoffer.com/development-o...   \n",
       "..               ...                                                ...   \n",
       "142  Netclan20241159  https://insights.blackcoffer.com/population-an...   \n",
       "143  Netclan20241160  https://insights.blackcoffer.com/google-lsa-ap...   \n",
       "144  Netclan20241161  https://insights.blackcoffer.com/healthcare-da...   \n",
       "145  Netclan20241162  https://insights.blackcoffer.com/budget-sales-...   \n",
       "146  Netclan20241163  https://insights.blackcoffer.com/amazon-buy-bo...   \n",
       "\n",
       "                                            title_file  \\\n",
       "0    article data/AI_and_ML-Based_YouTube_Analytics...   \n",
       "1    article data/Enhancing_Front-End_Features_and_...   \n",
       "2    article data/ROAS_Dashboard_for_Campaign-Wise_...   \n",
       "3                                                 None   \n",
       "4    article data/Development_of_EA_Robot_for_Autom...   \n",
       "..                                                 ...   \n",
       "142  article data/Population_and_Community_Survey_o...   \n",
       "143  article data/Google_LSA_API_Data_Automation_an...   \n",
       "144          article data/Healthcare_Data_Analysis.txt   \n",
       "145  article data/Budget,_Sales_KPI_Dashboard_using...   \n",
       "146  article data/Amazon_Buy_Bot,_an_Automation_AI_...   \n",
       "\n",
       "                                                  text  \\\n",
       "0    Title: AI and ML-Based YouTube Analytics and C...   \n",
       "1    Title: Enhancing Front-End Features and Functi...   \n",
       "2    Title: ROAS Dashboard for Campaign-Wise Google...   \n",
       "3                                                        \n",
       "4    Title: Development of EA Robot for Automated T...   \n",
       "..                                                 ...   \n",
       "142  Title: Population and Community Survey of Amer...   \n",
       "143  Title: Google LSA API Data Automation and Dash...   \n",
       "144  Title: Healthcare Data Analysis\\n\\nClient Back...   \n",
       "145  Title: Budget, Sales KPI Dashboard using Power...   \n",
       "146  Title: Amazon Buy Bot, an Automation AI tool t...   \n",
       "\n",
       "                                        positive_words  \\\n",
       "0                      [leading, integrated, Improved]   \n",
       "1    [Improved, leading, lead, patient, user-friend...   \n",
       "2    [leading, efficiently, streamlined, leading, c...   \n",
       "3                                                   []   \n",
       "4    [free, free, seamless, free, appropriate, like...   \n",
       "..                                                 ...   \n",
       "142  [leading, proper, strong, Sublime, Advanced, E...   \n",
       "143  [leading, lead, lead, lead, refresh, like, Sub...   \n",
       "144  [leading, survivor, better, patient, patient, ...   \n",
       "145                                                 []   \n",
       "146                                          [leading]   \n",
       "\n",
       "                                        negative_words  positive_word_count  \\\n",
       "0                                       [Cloud, Cloud]                    3   \n",
       "1    [static, issues, strictly, issues, strictly, C...                   15   \n",
       "2    [lacks, difficulties, cloud, slack, failure, C...                   10   \n",
       "3                                                   []                    0   \n",
       "4                                      [limited, risk]                   13   \n",
       "..                                                 ...                  ...   \n",
       "142            [unable, Cloud, plot, plot, plot, plot]                   12   \n",
       "143  [Regression, Cloud, Regression, missed, Cloud,...                   19   \n",
       "144  [died, death, death, manipulation, Death, died...                   10   \n",
       "145                                                 []                    0   \n",
       "146                                                 []                    1   \n",
       "\n",
       "     negative_word_count                                     filtered_words  \n",
       "0                      2  [title, ai, youtube, analytics, content, creat...  \n",
       "1                      6  [title, enhancing, features, functionality, im...  \n",
       "2                      8  [title, roas, dashboard, google, ads, budget, ...  \n",
       "3                      0                                                 []  \n",
       "4                      2  [title, development, ea, robot, automated, tra...  \n",
       "..                   ...                                                ...  \n",
       "142                    6  [title, population, community, survey, america...  \n",
       "143                   18  [title, google, lsa, api, data, automation, da...  \n",
       "144                    9  [title, healthcare, data, analysis, client, ba...  \n",
       "145                    0  [title, budget, sales, kpi, dashboard, using, ...  \n",
       "146                    0  [title, amazon, buy, bot, automation, ai, tool...  \n",
       "\n",
       "[147 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f09aadb-2663-45e8-bcfe-bf3460d4d492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [title, ai, youtube, analytics, content, creat...\n",
       "1      [title, enhancing, features, functionality, im...\n",
       "2      [title, roas, dashboard, google, ads, budget, ...\n",
       "3                                                     []\n",
       "4      [title, development, ea, robot, automated, tra...\n",
       "                             ...                        \n",
       "142    [title, population, community, survey, america...\n",
       "143    [title, google, lsa, api, data, automation, da...\n",
       "144    [title, healthcare, data, analysis, client, ba...\n",
       "145    [title, budget, sales, kpi, dashboard, using, ...\n",
       "146    [title, amazon, buy, bot, automation, ai, tool...\n",
       "Name: filtered_words, Length: 147, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['filtered_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed450e-f630-4ef3-a56e-bcca9549a30f",
   "metadata": {},
   "source": [
    "# feaure of complex words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fd95c57-ef46-4fbe-83c6-bb41332bf55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      filtered_words  \\\n",
      "0  [title, ai, youtube, analytics, content, creat...   \n",
      "1  [title, enhancing, features, functionality, im...   \n",
      "2  [title, roas, dashboard, google, ads, budget, ...   \n",
      "3                                                 []   \n",
      "4  [title, development, ea, robot, automated, tra...   \n",
      "\n",
      "                                       complex_words  complex_word_count  \n",
      "0  [analytics, creation, optimizing, subscriber, ...                  86  \n",
      "1  [enhancing, features, functionality, experienc...                 150  \n",
      "2  [backgroundclient, usaindustry, itproducts, se...                 106  \n",
      "3                                                 []                   0  \n",
      "4  [development, automated, objective, advisor, a...                 170  \n"
     ]
    }
   ],
   "source": [
    "import syllapy \n",
    "def count_complex_words_from_list(filtered_words):\n",
    "    complex_words = []\n",
    "    \n",
    "    # Iterate through the list of words\n",
    "    for word in filtered_words:\n",
    "        syllable_count = syllapy.count(word)  \n",
    "        if syllable_count >= 3: \n",
    "            complex_words.append(word)\n",
    "\n",
    "    return complex_words\n",
    "\n",
    "df['complex_words'] = df['filtered_words'].apply(count_complex_words_from_list)\n",
    "\n",
    "\n",
    "df['complex_word_count'] = df['complex_words'].apply(len)\n",
    "\n",
    "# Display the dataframe with the new feature\n",
    "print(df[['filtered_words', 'complex_words', 'complex_word_count']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9f26db8-1cf7-4922-8505-b8ad09318041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_count(text):\n",
    "    # Split the text into words and count the number of words\n",
    "    return len(text.split())\n",
    "\n",
    "# Apply the function to your dataframe\n",
    "df['word_count'] = df['text'].apply(calculate_word_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028bc8a7-9212-4b33-b284-c8b59995c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\gomes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the CMU Pronouncing Dictionary to get syllable counts for words\n",
    "nltk.download('cmudict')\n",
    "pron_dict = cmudict.dict()\n",
    "# Function to calculate FOG Index using existing columns\n",
    "def calculate_fog_index(row):\n",
    "    # Get the sentence count from the 'text' column\n",
    "    sentences = re.split(r'[.!?]', row['text'])\n",
    "    sentence_count = len([s for s in sentences if s.strip() != ''])  # Exclude empty sentences\n",
    "\n",
    "    # Get word_count and complex_word_count from the existing columns\n",
    "    word_count = row['word_count']\n",
    "    complex_word_count = row['complex_word_count']\n",
    "\n",
    "    # Calculate FOG index\n",
    "    if sentence_count == 0 or word_count == 0:  # Avoid division by zero\n",
    "        return 0\n",
    "    fog_index = 0.4 * ((word_count / sentence_count) + 100 * (complex_word_count / word_count))\n",
    "    return fog_index\n",
    "\n",
    "\n",
    "\n",
    "def calculate_avg_words_per_sentence(row):\n",
    "    sentences = row['text']  # Assuming 'text' is the original text column\n",
    "    sentence_list = nltk.sent_tokenize(sentences)  # Tokenize text into sentences\n",
    "    word_count = sum(len(nltk.word_tokenize(sentence)) for sentence in sentence_list)  # Total words in all sentences\n",
    "    sentence_count = len(sentence_list)  # Number of sentences\n",
    "\n",
    "    # To avoid division by zero if there are no sentences\n",
    "    if sentence_count == 0:\n",
    "        return 0\n",
    "    avg_words_per_sentence = word_count / sentence_count\n",
    "    return int(avg_words_per_sentence)  \n",
    "\n",
    "\n",
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    if word in pron_dict:\n",
    "        # Return the number of syllables in the word\n",
    "        return max([len(list(y for y in x if y[-1].isdigit())) for x in pron_dict[word]])\n",
    "    else:\n",
    "        # If the word is not found in the dictionary, we return an estimate based on the length of the word\n",
    "        return len([char for char in word if char in \"aeiou\"])\n",
    "\n",
    "# Function to calculate the percentage of complex words\n",
    "def calculate_complex_percentage(row):\n",
    "    complex_word_count = 0\n",
    "    words = row['filtered_words']  # Using the filtered_text (which is a list of words)\n",
    "    \n",
    "    for word in words:\n",
    "        if syllable_count(word) > 2:  # Consider words with more than 2 syllables as complex\n",
    "            complex_word_count += 1\n",
    "    \n",
    "    word_count = row['word_count']\n",
    "    \n",
    "    # Calculate Percentage of Complex Words\n",
    "    if word_count == 0:  # Avoid division by zero\n",
    "        return 0\n",
    "    percentage_complex_words = (complex_word_count / word_count) * 100\n",
    "    return percentage_complex_words\n",
    "\n",
    "# Apply the function to your dataframe to create the \"Avg Words Per Sentence\" column\n",
    "df['avg_words_per_sentence'] = df.apply(calculate_avg_words_per_sentence, axis=1)\n",
    "df['fog_index'] = df.apply(calculate_fog_index, axis=1)\n",
    "df['percentage_complex_words'] = df.apply(calculate_complex_percentage, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d63ee-a1d5-400c-9353-2099c2d62029",
   "metadata": {},
   "source": [
    "# Subjectivity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ade658-a17f-4899-808f-fe0f1b8f6afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to calculate subjectivity score\n",
    "def calculate_subjectivity_score(text):\n",
    "    blob = TextBlob(text)  # Create a TextBlob object\n",
    "    return blob.sentiment.subjectivity  # Get the subjectivity score\n",
    "\n",
    "# Apply the function to calculate subjectivity score for each row in the 'text' column\n",
    "df['subjectivity_score'] = df['text'].apply(calculate_subjectivity_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bed501b-9ac6-47b7-a79d-4beb440b34d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  Title: AI and ML-Based YouTube Analytics and C...   \n",
      "1  Title: Enhancing Front-End Features and Functi...   \n",
      "2  Title: ROAS Dashboard for Campaign-Wise Google...   \n",
      "3                                                      \n",
      "4  Title: Development of EA Robot for Automated T...   \n",
      "\n",
      "                              personal_pronouns_list  \n",
      "0  [IT, IT, IT, their, them, Our, them, their, IT...  \n",
      "1  [our, our, us, our, our, our, me, you, you, yo...  \n",
      "2                       [IT, IT, IT, it, it, IT, my]  \n",
      "3                                                 []  \n",
      "4                                       [it, It, my]  \n"
     ]
    }
   ],
   "source": [
    "personal_pronouns = ['I', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them', 'my', 'your', 'his', 'her', 'its', 'our', 'their']\n",
    "\n",
    "# Function to extract the list of personal pronouns from the text\n",
    "def extract_personal_pronouns(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Filter and collect personal pronouns found in the text\n",
    "    pronouns_in_text = [word for word in words if word.lower() in personal_pronouns]\n",
    "    \n",
    "    return pronouns_in_text\n",
    "\n",
    "# Apply the function to create a new column 'personal_pronouns_list' in the DataFrame\n",
    "df['personal_pronouns_list'] = df['text'].apply(extract_personal_pronouns)\n",
    "\n",
    "# Display the dataframe with the new feature\n",
    "print(df[['text', 'personal_pronouns_list']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd51ad85-aa9e-468c-8889-9b9c8825da23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>title_file</th>\n",
       "      <th>text</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>percentage_complex_words</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>personal_pronouns_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "      <td>article data/AI_and_ML-Based_YouTube_Analytics...</td>\n",
       "      <td>Title: AI and ML-Based YouTube Analytics and C...</td>\n",
       "      <td>[leading, integrated, Improved]</td>\n",
       "      <td>[Cloud, Cloud]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, ai, youtube, analytics, content, creat...</td>\n",
       "      <td>[analytics, creation, optimizing, subscriber, ...</td>\n",
       "      <td>86</td>\n",
       "      <td>275</td>\n",
       "      <td>65</td>\n",
       "      <td>18.620202</td>\n",
       "      <td>33.818182</td>\n",
       "      <td>0.283902</td>\n",
       "      <td>[IT, IT, IT, their, them, Our, them, their, IT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "      <td>article data/Enhancing_Front-End_Features_and_...</td>\n",
       "      <td>Title: Enhancing Front-End Features and Functi...</td>\n",
       "      <td>[Improved, leading, lead, patient, user-friend...</td>\n",
       "      <td>[static, issues, strictly, issues, strictly, C...</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>[title, enhancing, features, functionality, im...</td>\n",
       "      <td>[enhancing, features, functionality, experienc...</td>\n",
       "      <td>150</td>\n",
       "      <td>901</td>\n",
       "      <td>71</td>\n",
       "      <td>14.850177</td>\n",
       "      <td>16.759156</td>\n",
       "      <td>0.431083</td>\n",
       "      <td>[our, our, us, our, our, our, me, you, you, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "      <td>article data/ROAS_Dashboard_for_Campaign-Wise_...</td>\n",
       "      <td>Title: ROAS Dashboard for Campaign-Wise Google...</td>\n",
       "      <td>[leading, efficiently, streamlined, leading, c...</td>\n",
       "      <td>[lacks, difficulties, cloud, slack, failure, C...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[title, roas, dashboard, google, ads, budget, ...</td>\n",
       "      <td>[backgroundclient, usaindustry, itproducts, se...</td>\n",
       "      <td>106</td>\n",
       "      <td>461</td>\n",
       "      <td>32</td>\n",
       "      <td>15.556018</td>\n",
       "      <td>26.464208</td>\n",
       "      <td>0.264918</td>\n",
       "      <td>[IT, IT, IT, it, it, IT, my]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "      <td>article data/Development_of_EA_Robot_for_Autom...</td>\n",
       "      <td>Title: Development of EA Robot for Automated T...</td>\n",
       "      <td>[free, free, seamless, free, appropriate, like...</td>\n",
       "      <td>[limited, risk]</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, development, ea, robot, automated, tra...</td>\n",
       "      <td>[development, automated, objective, advisor, a...</td>\n",
       "      <td>170</td>\n",
       "      <td>723</td>\n",
       "      <td>24</td>\n",
       "      <td>14.146239</td>\n",
       "      <td>24.066390</td>\n",
       "      <td>0.316736</td>\n",
       "      <td>[it, It, my]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL  \\\n",
       "0  Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
       "1  Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...   \n",
       "2  Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...   \n",
       "3  Netclan20241020  https://insights.blackcoffer.com/efficient-pro...   \n",
       "4  Netclan20241021  https://insights.blackcoffer.com/development-o...   \n",
       "\n",
       "                                          title_file  \\\n",
       "0  article data/AI_and_ML-Based_YouTube_Analytics...   \n",
       "1  article data/Enhancing_Front-End_Features_and_...   \n",
       "2  article data/ROAS_Dashboard_for_Campaign-Wise_...   \n",
       "3                                               None   \n",
       "4  article data/Development_of_EA_Robot_for_Autom...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Title: AI and ML-Based YouTube Analytics and C...   \n",
       "1  Title: Enhancing Front-End Features and Functi...   \n",
       "2  Title: ROAS Dashboard for Campaign-Wise Google...   \n",
       "3                                                      \n",
       "4  Title: Development of EA Robot for Automated T...   \n",
       "\n",
       "                                      positive_words  \\\n",
       "0                    [leading, integrated, Improved]   \n",
       "1  [Improved, leading, lead, patient, user-friend...   \n",
       "2  [leading, efficiently, streamlined, leading, c...   \n",
       "3                                                 []   \n",
       "4  [free, free, seamless, free, appropriate, like...   \n",
       "\n",
       "                                      negative_words  positive_word_count  \\\n",
       "0                                     [Cloud, Cloud]                    3   \n",
       "1  [static, issues, strictly, issues, strictly, C...                   15   \n",
       "2  [lacks, difficulties, cloud, slack, failure, C...                   10   \n",
       "3                                                 []                    0   \n",
       "4                                    [limited, risk]                   13   \n",
       "\n",
       "   negative_word_count                                     filtered_words  \\\n",
       "0                    2  [title, ai, youtube, analytics, content, creat...   \n",
       "1                    6  [title, enhancing, features, functionality, im...   \n",
       "2                    8  [title, roas, dashboard, google, ads, budget, ...   \n",
       "3                    0                                                 []   \n",
       "4                    2  [title, development, ea, robot, automated, tra...   \n",
       "\n",
       "                                       complex_words  complex_word_count  \\\n",
       "0  [analytics, creation, optimizing, subscriber, ...                  86   \n",
       "1  [enhancing, features, functionality, experienc...                 150   \n",
       "2  [backgroundclient, usaindustry, itproducts, se...                 106   \n",
       "3                                                 []                   0   \n",
       "4  [development, automated, objective, advisor, a...                 170   \n",
       "\n",
       "   word_count  avg_words_per_sentence  fog_index  percentage_complex_words  \\\n",
       "0         275                      65  18.620202                 33.818182   \n",
       "1         901                      71  14.850177                 16.759156   \n",
       "2         461                      32  15.556018                 26.464208   \n",
       "3           0                       0   0.000000                  0.000000   \n",
       "4         723                      24  14.146239                 24.066390   \n",
       "\n",
       "   subjectivity_score                             personal_pronouns_list  \n",
       "0            0.283902  [IT, IT, IT, their, them, Our, them, their, IT...  \n",
       "1            0.431083  [our, our, us, our, our, our, me, you, you, yo...  \n",
       "2            0.264918                       [IT, IT, IT, it, it, IT, my]  \n",
       "3            0.000000                                                 []  \n",
       "4            0.316736                                       [it, It, my]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b652827-32ac-4291-8303-62d4e20eb624",
   "metadata": {},
   "source": [
    "# Syllabel per word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f56d9e0f-6b33-408a-8d0f-bee05cc4dc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>title_file</th>\n",
       "      <th>text</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>percentage_complex_words</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>personal_pronouns_list</th>\n",
       "      <th>syllables_per_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "      <td>article data/AI_and_ML-Based_YouTube_Analytics...</td>\n",
       "      <td>Title: AI and ML-Based YouTube Analytics and C...</td>\n",
       "      <td>[leading, integrated, Improved]</td>\n",
       "      <td>[Cloud, Cloud]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, ai, youtube, analytics, content, creat...</td>\n",
       "      <td>[analytics, creation, optimizing, subscriber, ...</td>\n",
       "      <td>86</td>\n",
       "      <td>275</td>\n",
       "      <td>65</td>\n",
       "      <td>18.620202</td>\n",
       "      <td>33.818182</td>\n",
       "      <td>0.283902</td>\n",
       "      <td>[IT, IT, IT, their, them, Our, them, their, IT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "      <td>article data/Enhancing_Front-End_Features_and_...</td>\n",
       "      <td>Title: Enhancing Front-End Features and Functi...</td>\n",
       "      <td>[Improved, leading, lead, patient, user-friend...</td>\n",
       "      <td>[static, issues, strictly, issues, strictly, C...</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>[title, enhancing, features, functionality, im...</td>\n",
       "      <td>[enhancing, features, functionality, experienc...</td>\n",
       "      <td>150</td>\n",
       "      <td>901</td>\n",
       "      <td>71</td>\n",
       "      <td>14.850177</td>\n",
       "      <td>16.759156</td>\n",
       "      <td>0.431083</td>\n",
       "      <td>[our, our, us, our, our, our, me, you, you, yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "      <td>article data/ROAS_Dashboard_for_Campaign-Wise_...</td>\n",
       "      <td>Title: ROAS Dashboard for Campaign-Wise Google...</td>\n",
       "      <td>[leading, efficiently, streamlined, leading, c...</td>\n",
       "      <td>[lacks, difficulties, cloud, slack, failure, C...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[title, roas, dashboard, google, ads, budget, ...</td>\n",
       "      <td>[backgroundclient, usaindustry, itproducts, se...</td>\n",
       "      <td>106</td>\n",
       "      <td>461</td>\n",
       "      <td>32</td>\n",
       "      <td>15.556018</td>\n",
       "      <td>26.464208</td>\n",
       "      <td>0.264918</td>\n",
       "      <td>[IT, IT, IT, it, it, IT, my]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "      <td>article data/Development_of_EA_Robot_for_Autom...</td>\n",
       "      <td>Title: Development of EA Robot for Automated T...</td>\n",
       "      <td>[free, free, seamless, free, appropriate, like...</td>\n",
       "      <td>[limited, risk]</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, development, ea, robot, automated, tra...</td>\n",
       "      <td>[development, automated, objective, advisor, a...</td>\n",
       "      <td>170</td>\n",
       "      <td>723</td>\n",
       "      <td>24</td>\n",
       "      <td>14.146239</td>\n",
       "      <td>24.066390</td>\n",
       "      <td>0.316736</td>\n",
       "      <td>[it, It, my]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL  \\\n",
       "0  Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
       "1  Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...   \n",
       "2  Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...   \n",
       "3  Netclan20241020  https://insights.blackcoffer.com/efficient-pro...   \n",
       "4  Netclan20241021  https://insights.blackcoffer.com/development-o...   \n",
       "\n",
       "                                          title_file  \\\n",
       "0  article data/AI_and_ML-Based_YouTube_Analytics...   \n",
       "1  article data/Enhancing_Front-End_Features_and_...   \n",
       "2  article data/ROAS_Dashboard_for_Campaign-Wise_...   \n",
       "3                                               None   \n",
       "4  article data/Development_of_EA_Robot_for_Autom...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Title: AI and ML-Based YouTube Analytics and C...   \n",
       "1  Title: Enhancing Front-End Features and Functi...   \n",
       "2  Title: ROAS Dashboard for Campaign-Wise Google...   \n",
       "3                                                      \n",
       "4  Title: Development of EA Robot for Automated T...   \n",
       "\n",
       "                                      positive_words  \\\n",
       "0                    [leading, integrated, Improved]   \n",
       "1  [Improved, leading, lead, patient, user-friend...   \n",
       "2  [leading, efficiently, streamlined, leading, c...   \n",
       "3                                                 []   \n",
       "4  [free, free, seamless, free, appropriate, like...   \n",
       "\n",
       "                                      negative_words  positive_word_count  \\\n",
       "0                                     [Cloud, Cloud]                    3   \n",
       "1  [static, issues, strictly, issues, strictly, C...                   15   \n",
       "2  [lacks, difficulties, cloud, slack, failure, C...                   10   \n",
       "3                                                 []                    0   \n",
       "4                                    [limited, risk]                   13   \n",
       "\n",
       "   negative_word_count                                     filtered_words  \\\n",
       "0                    2  [title, ai, youtube, analytics, content, creat...   \n",
       "1                    6  [title, enhancing, features, functionality, im...   \n",
       "2                    8  [title, roas, dashboard, google, ads, budget, ...   \n",
       "3                    0                                                 []   \n",
       "4                    2  [title, development, ea, robot, automated, tra...   \n",
       "\n",
       "                                       complex_words  complex_word_count  \\\n",
       "0  [analytics, creation, optimizing, subscriber, ...                  86   \n",
       "1  [enhancing, features, functionality, experienc...                 150   \n",
       "2  [backgroundclient, usaindustry, itproducts, se...                 106   \n",
       "3                                                 []                   0   \n",
       "4  [development, automated, objective, advisor, a...                 170   \n",
       "\n",
       "   word_count  avg_words_per_sentence  fog_index  percentage_complex_words  \\\n",
       "0         275                      65  18.620202                 33.818182   \n",
       "1         901                      71  14.850177                 16.759156   \n",
       "2         461                      32  15.556018                 26.464208   \n",
       "3           0                       0   0.000000                  0.000000   \n",
       "4         723                      24  14.146239                 24.066390   \n",
       "\n",
       "   subjectivity_score                             personal_pronouns_list  \\\n",
       "0            0.283902  [IT, IT, IT, their, them, Our, them, their, IT...   \n",
       "1            0.431083  [our, our, us, our, our, our, me, you, you, yo...   \n",
       "2            0.264918                       [IT, IT, IT, it, it, IT, my]   \n",
       "3            0.000000                                                 []   \n",
       "4            0.316736                                       [it, It, my]   \n",
       "\n",
       "   syllables_per_word  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   0  \n",
       "4                   1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_syllables(word):\n",
    "    return syllapy.count(word)\n",
    "\n",
    "# Function to calculate average syllables per word in a text\n",
    "def syllables_per_word(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Calculate total syllables in all words\n",
    "    total_syllables = sum(count_syllables(word) for word in words)\n",
    "    \n",
    "    # Calculate average syllables per word (to avoid division by zero)\n",
    "    avg_syllables = total_syllables / len(words) if words else 0\n",
    "    \n",
    "    return int(avg_syllables)\n",
    "\n",
    "# Apply the function to create a new column 'syllables_per_word' in the DataFrame\n",
    "df['syllables_per_word'] = df['text'].apply(syllables_per_word)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4559ed-814a-4342-b80d-89213f4cf38a",
   "metadata": {},
   "source": [
    "# Polarity score, Average sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f06b448-f530-42ca-af80-4fc2d7582bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>title_file</th>\n",
       "      <th>text</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>percentage_complex_words</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>personal_pronouns_list</th>\n",
       "      <th>syllables_per_word</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "      <td>article data/AI_and_ML-Based_YouTube_Analytics...</td>\n",
       "      <td>Title: AI and ML-Based YouTube Analytics and C...</td>\n",
       "      <td>[leading, integrated, Improved]</td>\n",
       "      <td>[Cloud, Cloud]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, ai, youtube, analytics, content, creat...</td>\n",
       "      <td>[analytics, creation, optimizing, subscriber, ...</td>\n",
       "      <td>86</td>\n",
       "      <td>275</td>\n",
       "      <td>65</td>\n",
       "      <td>18.620202</td>\n",
       "      <td>33.818182</td>\n",
       "      <td>0.283902</td>\n",
       "      <td>[IT, IT, IT, their, them, Our, them, their, IT...</td>\n",
       "      <td>1</td>\n",
       "      <td>52.200000</td>\n",
       "      <td>0.027462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "      <td>article data/Enhancing_Front-End_Features_and_...</td>\n",
       "      <td>Title: Enhancing Front-End Features and Functi...</td>\n",
       "      <td>[Improved, leading, lead, patient, user-friend...</td>\n",
       "      <td>[static, issues, strictly, issues, strictly, C...</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>[title, enhancing, features, functionality, im...</td>\n",
       "      <td>[enhancing, features, functionality, experienc...</td>\n",
       "      <td>150</td>\n",
       "      <td>901</td>\n",
       "      <td>71</td>\n",
       "      <td>14.850177</td>\n",
       "      <td>16.759156</td>\n",
       "      <td>0.431083</td>\n",
       "      <td>[our, our, us, our, our, our, me, you, you, yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>61.214286</td>\n",
       "      <td>0.166357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "      <td>article data/ROAS_Dashboard_for_Campaign-Wise_...</td>\n",
       "      <td>Title: ROAS Dashboard for Campaign-Wise Google...</td>\n",
       "      <td>[leading, efficiently, streamlined, leading, c...</td>\n",
       "      <td>[lacks, difficulties, cloud, slack, failure, C...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[title, roas, dashboard, google, ads, budget, ...</td>\n",
       "      <td>[backgroundclient, usaindustry, itproducts, se...</td>\n",
       "      <td>106</td>\n",
       "      <td>461</td>\n",
       "      <td>32</td>\n",
       "      <td>15.556018</td>\n",
       "      <td>26.464208</td>\n",
       "      <td>0.264918</td>\n",
       "      <td>[IT, IT, IT, it, it, IT, my]</td>\n",
       "      <td>1</td>\n",
       "      <td>27.687500</td>\n",
       "      <td>0.065501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "      <td>article data/Development_of_EA_Robot_for_Autom...</td>\n",
       "      <td>Title: Development of EA Robot for Automated T...</td>\n",
       "      <td>[free, free, seamless, free, appropriate, like...</td>\n",
       "      <td>[limited, risk]</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, development, ea, robot, automated, tra...</td>\n",
       "      <td>[development, automated, objective, advisor, a...</td>\n",
       "      <td>170</td>\n",
       "      <td>723</td>\n",
       "      <td>24</td>\n",
       "      <td>14.146239</td>\n",
       "      <td>24.066390</td>\n",
       "      <td>0.316736</td>\n",
       "      <td>[it, It, my]</td>\n",
       "      <td>1</td>\n",
       "      <td>19.657143</td>\n",
       "      <td>0.118347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            URL_ID                                                URL  \\\n",
       "0  Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
       "1  Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...   \n",
       "2  Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...   \n",
       "3  Netclan20241020  https://insights.blackcoffer.com/efficient-pro...   \n",
       "4  Netclan20241021  https://insights.blackcoffer.com/development-o...   \n",
       "\n",
       "                                          title_file  \\\n",
       "0  article data/AI_and_ML-Based_YouTube_Analytics...   \n",
       "1  article data/Enhancing_Front-End_Features_and_...   \n",
       "2  article data/ROAS_Dashboard_for_Campaign-Wise_...   \n",
       "3                                               None   \n",
       "4  article data/Development_of_EA_Robot_for_Autom...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Title: AI and ML-Based YouTube Analytics and C...   \n",
       "1  Title: Enhancing Front-End Features and Functi...   \n",
       "2  Title: ROAS Dashboard for Campaign-Wise Google...   \n",
       "3                                                      \n",
       "4  Title: Development of EA Robot for Automated T...   \n",
       "\n",
       "                                      positive_words  \\\n",
       "0                    [leading, integrated, Improved]   \n",
       "1  [Improved, leading, lead, patient, user-friend...   \n",
       "2  [leading, efficiently, streamlined, leading, c...   \n",
       "3                                                 []   \n",
       "4  [free, free, seamless, free, appropriate, like...   \n",
       "\n",
       "                                      negative_words  positive_word_count  \\\n",
       "0                                     [Cloud, Cloud]                    3   \n",
       "1  [static, issues, strictly, issues, strictly, C...                   15   \n",
       "2  [lacks, difficulties, cloud, slack, failure, C...                   10   \n",
       "3                                                 []                    0   \n",
       "4                                    [limited, risk]                   13   \n",
       "\n",
       "   negative_word_count                                     filtered_words  \\\n",
       "0                    2  [title, ai, youtube, analytics, content, creat...   \n",
       "1                    6  [title, enhancing, features, functionality, im...   \n",
       "2                    8  [title, roas, dashboard, google, ads, budget, ...   \n",
       "3                    0                                                 []   \n",
       "4                    2  [title, development, ea, robot, automated, tra...   \n",
       "\n",
       "                                       complex_words  complex_word_count  \\\n",
       "0  [analytics, creation, optimizing, subscriber, ...                  86   \n",
       "1  [enhancing, features, functionality, experienc...                 150   \n",
       "2  [backgroundclient, usaindustry, itproducts, se...                 106   \n",
       "3                                                 []                   0   \n",
       "4  [development, automated, objective, advisor, a...                 170   \n",
       "\n",
       "   word_count  avg_words_per_sentence  fog_index  percentage_complex_words  \\\n",
       "0         275                      65  18.620202                 33.818182   \n",
       "1         901                      71  14.850177                 16.759156   \n",
       "2         461                      32  15.556018                 26.464208   \n",
       "3           0                       0   0.000000                  0.000000   \n",
       "4         723                      24  14.146239                 24.066390   \n",
       "\n",
       "   subjectivity_score                             personal_pronouns_list  \\\n",
       "0            0.283902  [IT, IT, IT, their, them, Our, them, their, IT...   \n",
       "1            0.431083  [our, our, us, our, our, our, me, you, you, yo...   \n",
       "2            0.264918                       [IT, IT, IT, it, it, IT, my]   \n",
       "3            0.000000                                                 []   \n",
       "4            0.316736                                       [it, It, my]   \n",
       "\n",
       "   syllables_per_word  avg_sentence_length  polarity_score  \n",
       "0                   1            52.200000        0.027462  \n",
       "1                   1            61.214286        0.166357  \n",
       "2                   1            27.687500        0.065501  \n",
       "3                   0             0.000000        0.000000  \n",
       "4                   1            19.657143        0.118347  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_polarity_score(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity  # Polarity score between -1 and 1\n",
    "\n",
    "# Apply the function to create a new column 'polarity_score' in the DataFrame\n",
    "def calculate_avg_sentence_length(text):\n",
    "    sentences = sent_tokenize(text)  # Tokenize text into sentences\n",
    "    words = word_tokenize(text)      # Tokenize text into words\n",
    "    word_count = len([word for word in words if word.isalnum()])  # Count only words, excluding punctuation\n",
    "    sentence_count = len(sentences)  # Count number of sentences\n",
    "    avg_sentence_length = word_count / sentence_count if sentence_count > 0 else 0  # Calculate average length\n",
    "    return avg_sentence_length\n",
    "\n",
    "# Apply the function to create a new column 'avg_sentence_length' in the DataFrame\n",
    "df['avg_sentence_length'] = df['text'].apply(calculate_avg_sentence_length)\n",
    "\n",
    "df['polarity_score'] = df['text'].apply(calculate_polarity_score)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "400302fa-43a4-43db-b0e9-33d4ddcc2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['title_file','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c4c6d15-5483-48ae-9456-54c5341b4aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_blackcoffer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7577c711-1dea-43ca-9c64-2711f627b64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>positive_word_count</th>\n",
       "      <th>negative_word_count</th>\n",
       "      <th>filtered_words</th>\n",
       "      <th>complex_words</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>percentage_complex_words</th>\n",
       "      <th>subjectivity_score</th>\n",
       "      <th>personal_pronouns_list</th>\n",
       "      <th>syllables_per_word</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netclan20241017</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-and-ml-bas...</td>\n",
       "      <td>[leading, integrated, Improved]</td>\n",
       "      <td>[Cloud, Cloud]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, ai, youtube, analytics, content, creat...</td>\n",
       "      <td>[analytics, creation, optimizing, subscriber, ...</td>\n",
       "      <td>86</td>\n",
       "      <td>275</td>\n",
       "      <td>65</td>\n",
       "      <td>18.620202</td>\n",
       "      <td>33.818182</td>\n",
       "      <td>0.283902</td>\n",
       "      <td>[IT, IT, IT, their, them, Our, them, their, IT...</td>\n",
       "      <td>1</td>\n",
       "      <td>52.200000</td>\n",
       "      <td>0.027462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netclan20241018</td>\n",
       "      <td>https://insights.blackcoffer.com/enhancing-fro...</td>\n",
       "      <td>[Improved, leading, lead, patient, user-friend...</td>\n",
       "      <td>[static, issues, strictly, issues, strictly, C...</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>[title, enhancing, features, functionality, im...</td>\n",
       "      <td>[enhancing, features, functionality, experienc...</td>\n",
       "      <td>150</td>\n",
       "      <td>901</td>\n",
       "      <td>71</td>\n",
       "      <td>14.850177</td>\n",
       "      <td>16.759156</td>\n",
       "      <td>0.431083</td>\n",
       "      <td>[our, our, us, our, our, our, me, you, you, yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>61.214286</td>\n",
       "      <td>0.166357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netclan20241019</td>\n",
       "      <td>https://insights.blackcoffer.com/roas-dashboar...</td>\n",
       "      <td>[leading, efficiently, streamlined, leading, c...</td>\n",
       "      <td>[lacks, difficulties, cloud, slack, failure, C...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>[title, roas, dashboard, google, ads, budget, ...</td>\n",
       "      <td>[backgroundclient, usaindustry, itproducts, se...</td>\n",
       "      <td>106</td>\n",
       "      <td>461</td>\n",
       "      <td>32</td>\n",
       "      <td>15.556018</td>\n",
       "      <td>26.464208</td>\n",
       "      <td>0.264918</td>\n",
       "      <td>[IT, IT, IT, it, it, IT, my]</td>\n",
       "      <td>1</td>\n",
       "      <td>27.687500</td>\n",
       "      <td>0.065501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netclan20241020</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-pro...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netclan20241021</td>\n",
       "      <td>https://insights.blackcoffer.com/development-o...</td>\n",
       "      <td>[free, free, seamless, free, appropriate, like...</td>\n",
       "      <td>[limited, risk]</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>[title, development, ea, robot, automated, tra...</td>\n",
       "      <td>[development, automated, objective, advisor, a...</td>\n",
       "      <td>170</td>\n",
       "      <td>723</td>\n",
       "      <td>24</td>\n",
       "      <td>14.146239</td>\n",
       "      <td>24.066390</td>\n",
       "      <td>0.316736</td>\n",
       "      <td>[it, It, my]</td>\n",
       "      <td>1</td>\n",
       "      <td>19.657143</td>\n",
       "      <td>0.118347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Netclan20241159</td>\n",
       "      <td>https://insights.blackcoffer.com/population-an...</td>\n",
       "      <td>[leading, proper, strong, Sublime, Advanced, E...</td>\n",
       "      <td>[unable, Cloud, plot, plot, plot, plot]</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>[title, population, community, survey, america...</td>\n",
       "      <td>[population, community, america, backgroundcli...</td>\n",
       "      <td>207</td>\n",
       "      <td>905</td>\n",
       "      <td>80</td>\n",
       "      <td>18.199171</td>\n",
       "      <td>22.651934</td>\n",
       "      <td>0.399814</td>\n",
       "      <td>[them, their, them, we, our, my, It]</td>\n",
       "      <td>1</td>\n",
       "      <td>71.750000</td>\n",
       "      <td>0.062403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Netclan20241160</td>\n",
       "      <td>https://insights.blackcoffer.com/google-lsa-ap...</td>\n",
       "      <td>[leading, lead, lead, lead, refresh, like, Sub...</td>\n",
       "      <td>[Regression, Cloud, Regression, missed, Cloud,...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>[title, google, lsa, api, data, automation, da...</td>\n",
       "      <td>[automation, dashboarding, backgroundclient, m...</td>\n",
       "      <td>278</td>\n",
       "      <td>1372</td>\n",
       "      <td>46</td>\n",
       "      <td>16.175545</td>\n",
       "      <td>21.720117</td>\n",
       "      <td>0.251640</td>\n",
       "      <td>[its, their, them, their, it, we, it, our, my,...</td>\n",
       "      <td>1</td>\n",
       "      <td>40.375000</td>\n",
       "      <td>0.043007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Netclan20241161</td>\n",
       "      <td>https://insights.blackcoffer.com/healthcare-da...</td>\n",
       "      <td>[leading, survivor, better, patient, patient, ...</td>\n",
       "      <td>[died, death, death, manipulation, Death, died...</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>[title, healthcare, data, analysis, client, ba...</td>\n",
       "      <td>[analysis, backgroundclient, usaindustry, cons...</td>\n",
       "      <td>66</td>\n",
       "      <td>415</td>\n",
       "      <td>56</td>\n",
       "      <td>13.578837</td>\n",
       "      <td>15.903614</td>\n",
       "      <td>0.338480</td>\n",
       "      <td>[we, us, we, we, us, we, we, we, us, our, we, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>0.026348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Netclan20241162</td>\n",
       "      <td>https://insights.blackcoffer.com/budget-sales-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[title, budget, sales, kpi, dashboard, using, ...</td>\n",
       "      <td>[descriptionweekly, clustered, actual, actual,...</td>\n",
       "      <td>44</td>\n",
       "      <td>163</td>\n",
       "      <td>186</td>\n",
       "      <td>75.997546</td>\n",
       "      <td>26.380368</td>\n",
       "      <td>0.414035</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>-0.008772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Netclan20241163</td>\n",
       "      <td>https://insights.blackcoffer.com/amazon-buy-bo...</td>\n",
       "      <td>[leading]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[title, amazon, buy, bot, automation, ai, tool...</td>\n",
       "      <td>[amazon, automation, backgroundclient, consult...</td>\n",
       "      <td>39</td>\n",
       "      <td>160</td>\n",
       "      <td>42</td>\n",
       "      <td>17.750000</td>\n",
       "      <td>24.375000</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>[we, it]</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.001587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              URL_ID                                                URL  \\\n",
       "0    Netclan20241017  https://insights.blackcoffer.com/ai-and-ml-bas...   \n",
       "1    Netclan20241018  https://insights.blackcoffer.com/enhancing-fro...   \n",
       "2    Netclan20241019  https://insights.blackcoffer.com/roas-dashboar...   \n",
       "3    Netclan20241020  https://insights.blackcoffer.com/efficient-pro...   \n",
       "4    Netclan20241021  https://insights.blackcoffer.com/development-o...   \n",
       "..               ...                                                ...   \n",
       "142  Netclan20241159  https://insights.blackcoffer.com/population-an...   \n",
       "143  Netclan20241160  https://insights.blackcoffer.com/google-lsa-ap...   \n",
       "144  Netclan20241161  https://insights.blackcoffer.com/healthcare-da...   \n",
       "145  Netclan20241162  https://insights.blackcoffer.com/budget-sales-...   \n",
       "146  Netclan20241163  https://insights.blackcoffer.com/amazon-buy-bo...   \n",
       "\n",
       "                                        positive_words  \\\n",
       "0                      [leading, integrated, Improved]   \n",
       "1    [Improved, leading, lead, patient, user-friend...   \n",
       "2    [leading, efficiently, streamlined, leading, c...   \n",
       "3                                                   []   \n",
       "4    [free, free, seamless, free, appropriate, like...   \n",
       "..                                                 ...   \n",
       "142  [leading, proper, strong, Sublime, Advanced, E...   \n",
       "143  [leading, lead, lead, lead, refresh, like, Sub...   \n",
       "144  [leading, survivor, better, patient, patient, ...   \n",
       "145                                                 []   \n",
       "146                                          [leading]   \n",
       "\n",
       "                                        negative_words  positive_word_count  \\\n",
       "0                                       [Cloud, Cloud]                    3   \n",
       "1    [static, issues, strictly, issues, strictly, C...                   15   \n",
       "2    [lacks, difficulties, cloud, slack, failure, C...                   10   \n",
       "3                                                   []                    0   \n",
       "4                                      [limited, risk]                   13   \n",
       "..                                                 ...                  ...   \n",
       "142            [unable, Cloud, plot, plot, plot, plot]                   12   \n",
       "143  [Regression, Cloud, Regression, missed, Cloud,...                   19   \n",
       "144  [died, death, death, manipulation, Death, died...                   10   \n",
       "145                                                 []                    0   \n",
       "146                                                 []                    1   \n",
       "\n",
       "     negative_word_count                                     filtered_words  \\\n",
       "0                      2  [title, ai, youtube, analytics, content, creat...   \n",
       "1                      6  [title, enhancing, features, functionality, im...   \n",
       "2                      8  [title, roas, dashboard, google, ads, budget, ...   \n",
       "3                      0                                                 []   \n",
       "4                      2  [title, development, ea, robot, automated, tra...   \n",
       "..                   ...                                                ...   \n",
       "142                    6  [title, population, community, survey, america...   \n",
       "143                   18  [title, google, lsa, api, data, automation, da...   \n",
       "144                    9  [title, healthcare, data, analysis, client, ba...   \n",
       "145                    0  [title, budget, sales, kpi, dashboard, using, ...   \n",
       "146                    0  [title, amazon, buy, bot, automation, ai, tool...   \n",
       "\n",
       "                                         complex_words  complex_word_count  \\\n",
       "0    [analytics, creation, optimizing, subscriber, ...                  86   \n",
       "1    [enhancing, features, functionality, experienc...                 150   \n",
       "2    [backgroundclient, usaindustry, itproducts, se...                 106   \n",
       "3                                                   []                   0   \n",
       "4    [development, automated, objective, advisor, a...                 170   \n",
       "..                                                 ...                 ...   \n",
       "142  [population, community, america, backgroundcli...                 207   \n",
       "143  [automation, dashboarding, backgroundclient, m...                 278   \n",
       "144  [analysis, backgroundclient, usaindustry, cons...                  66   \n",
       "145  [descriptionweekly, clustered, actual, actual,...                  44   \n",
       "146  [amazon, automation, backgroundclient, consult...                  39   \n",
       "\n",
       "     word_count  avg_words_per_sentence  fog_index  percentage_complex_words  \\\n",
       "0           275                      65  18.620202                 33.818182   \n",
       "1           901                      71  14.850177                 16.759156   \n",
       "2           461                      32  15.556018                 26.464208   \n",
       "3             0                       0   0.000000                  0.000000   \n",
       "4           723                      24  14.146239                 24.066390   \n",
       "..          ...                     ...        ...                       ...   \n",
       "142         905                      80  18.199171                 22.651934   \n",
       "143        1372                      46  16.175545                 21.720117   \n",
       "144         415                      56  13.578837                 15.903614   \n",
       "145         163                     186  75.997546                 26.380368   \n",
       "146         160                      42  17.750000                 24.375000   \n",
       "\n",
       "     subjectivity_score                             personal_pronouns_list  \\\n",
       "0              0.283902  [IT, IT, IT, their, them, Our, them, their, IT...   \n",
       "1              0.431083  [our, our, us, our, our, our, me, you, you, yo...   \n",
       "2              0.264918                       [IT, IT, IT, it, it, IT, my]   \n",
       "3              0.000000                                                 []   \n",
       "4              0.316736                                       [it, It, my]   \n",
       "..                  ...                                                ...   \n",
       "142            0.399814               [them, their, them, we, our, my, It]   \n",
       "143            0.251640  [its, their, them, their, it, we, it, our, my,...   \n",
       "144            0.338480  [we, us, we, we, us, we, we, we, us, our, we, ...   \n",
       "145            0.414035                                                 []   \n",
       "146            0.253968                                           [we, it]   \n",
       "\n",
       "     syllables_per_word  avg_sentence_length  polarity_score  \n",
       "0                     1            52.200000        0.027462  \n",
       "1                     1            61.214286        0.166357  \n",
       "2                     1            27.687500        0.065501  \n",
       "3                     0             0.000000        0.000000  \n",
       "4                     1            19.657143        0.118347  \n",
       "..                  ...                  ...             ...  \n",
       "142                   1            71.750000        0.062403  \n",
       "143                   1            40.375000        0.043007  \n",
       "144                   1            50.250000        0.026348  \n",
       "145                   1           143.000000       -0.008772  \n",
       "146                   1            38.000000        0.001587  \n",
       "\n",
       "[147 rows x 18 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45b9703-0862-4e16-9f2f-10d911e0ecee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e6c01-7ec3-47e2-b1c2-df26c5956709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3df062-59c7-440d-bd6a-22fb6e8bf156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c047d-8631-4405-a1d1-75c14f921a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca172a72-772c-491e-ab6d-05d689b513ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b3d361-01d4-45e2-8fc8-9069a3a7e8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ad4b9-6aa9-46e2-b7cc-d9eef923f861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5aaf3-9938-4d1a-b8fc-113724ccbd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc7b28-26f5-4b04-bbb5-ba8dd0362195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea89b0-541f-47ca-8393-71c73a643481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218cc9f7-2b50-407a-a0af-d51196810b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6099771-20dd-4d6b-b6b4-4a89ff618508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0834bc1-a758-43f1-90de-c9a11a3599eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4eee3e-e94e-4a66-9815-8edfc47c4941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa190a-9c73-46f8-a260-bf7bfd154ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f5bb8-9a97-48ec-ab66-9a93a97f45ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
